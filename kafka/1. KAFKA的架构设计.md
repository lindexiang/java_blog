[toc]
# 1. 定义

KAFKA是基于发布订阅的消息队列，用户大数据实时处理的领域。和RocketMQ处理的领域不同。

使用消息队列的好处

1. 解耦 将复杂的系统分解成2个模块处理
2. 持久化 系统的进程挂了，消息不会丢失
3. 缓冲和峰值处理能力  生产者和消费者速度不匹配 还有应对突发的流量 。

消息队列是一对多的模型，生产将消息发布到Topic中，可以有多个消费者订阅消息。发布到Topic的消息会被所有的订阅者消费，被消费的消息不会被Topic删除。



![](https://medesqure.oss-cn-hangzhou.aliyuncs.com/img/20200712233655.png)

如上图所示，一个典型的kafka集群中包含若干producer若干broker（Kafka支持水平扩展，一般broker数量越多，集群吞吐率越高），若干consumer group，以及一个Zookeeper集群。Kafka通过Zookeeper管理集群配置，选举leader，以及在consumer group发生变化时进行rebalance。producer使用push模式将消息发布到broker，consumer使用pull模式从broker订阅并消费消息。 　　

## 1.1 pull模式和push模式的区别

push模式很难适应消费速度不同的消费者。但是消费的速度是broker控制的。push模式可以最快的速度传递消息，容易造成consumer来不及处理消息。会造成consumer拒绝服务和网络阻塞。pull模式可以根据消费者的消费能力适当的速度消费消息。

# 2.KAFKA的架构

基本概念

![](https://medesqure.oss-cn-hangzhou.aliyuncs.com/img/20200716214111.png)

- Producer/ Consumer  生产者和消费者
- Consumer Group 消费者组 **消费者组中的每个消费者负责消费不同分区的数据，提高消费能力。一个分区只能由一个消费者消费，消费者组之间互不影响。所有的消费者都属于一个消费者组，组是逻辑上的一个订阅者。**
- Broker  集群的一个节点。一个集群有多个Broker 一个Broker可以存多个Topic
- Topic 一个队列，Topic将消息分类，生产者和消费者面向的是Topic。
- Partition   Topic是逻辑队列，Partition是 物理队列。为了提高并发能力，一个Topic会被分成多个Partation分布在多个Broker上。每个Partition是一个有序队列
- Leader/Follower Partition的主从节点，Leader做数据的交互，Follower 主从同步和故障转移
- Offset   每个Partition都是由一系列有序、不可变的消息组成。被追加到里面。partition的每个消息都有一个offset唯一标识。
- Segment partition由多个Segment组成。

![](https://medesqure.oss-cn-hangzhou.aliyuncs.com/img/20200712223020.png)

![](https://medesqure.oss-cn-hangzhou.aliyuncs.com/img/20200713002732.png)

## 2.1 KAFKA投递消息

**每个消息都是被append到partition中，是属于顺序写磁盘，效率非常高。(经过验证，顺序写磁盘效率比随机写内存的效率高，这时kafka高吞吐率的重要原因)**

每个消息被发送到broker中，会根据路由规则被存储到一个partition中。如果规则设置合理，所有的消息都会被分布到不同的partition中，**实现了水平的扩展。在创建topic可以指定partition的默认数量。**

kafka集群会保留所有的消息，无论消息被消费与否。因为磁盘的限制，需要删除一些旧数据。kafka提供了2中策略。

1. 基于时间 比如删除一周之前的数据
2. 基于文件大小 比如partition文件超过1GB就删除旧数据

注意点:

**kafka读取消息的事件复杂度为O(1)，和文件的大小无关。因为在索引文件中保存了物理偏移地址通过mmap技术直接读取内容。**

kafka会为consumer group保留一些元数据和当前消费的进度offset。**但是这个offset是由consumer控制。所以kafka是无状态的，**不需要标记那些消息被那些consumer消费过。所以不需要锁机制，为搞吞吐率提供了保障。

## 2.2 消息的存储机制

Topic在逻辑上可以认为是一个Queue。每个消息都要指定Topic。每个消息都要指明放在哪个Queue中。为了提搞吞吐率，将topic在物理上分成多个partition。**每个partition都对应一个文件夹**。该文件夹上存储了该partition所有的消息和索引文件。



![](https://medesqure.oss-cn-hangzhou.aliyuncs.com/img/20200712232808.png)



## 2.2.1 Segment文件的存储结构

1. 组成 
   一个segment会有.index索引文件和.log的数据文件。
2. 命名规则
   segment从0开始，后续每个文件都是上一个segment最后一条消息的offset。数值为64位。

当创建一个partition并往里面写数据后会出现如下的一个文件夹。

![](https://medesqure.oss-cn-hangzhou.aliyuncs.com/img/20200713000222.png)

并且一个segment中的index和log的对应关系如下所示

![](https://medesqure.oss-cn-hangzhou.aliyuncs.com/img/20200713000259.png)

**index文件存储了大量的元数据，数据文件存储了信息，index文件中的元数据指向的是数据文件中message的物理偏移地址。**

例如index文件中的元数据3，497为例，依在表示在log文件中的第3个偏移，其该消息在物理地址中的偏移量为497。

### 2.2.2 在partition中如何通过offset查找message

例如查找offset为368776的message

1. 二分查找partition文件夹下的segment的index文件，按照偏移量定位到指定的segment
2. 在index中通过offset和offset0计算出在文件中的偏移。并通过index存储的物理偏移地址直接读取message。

**index文件通过稀疏索引存储的方式来减少索引文件的大小，并通过mmap的技术直接操作内存，index文件存储的是log文件每个message的物理偏移地址指针。**

## 2.3 Producer的消息路由

Producer在发送消息到broker时，可以选择投递到不同的partition中。机制有如下2种

1. Hash机制 根据key的哈希值和partition的数量取余获取
2. Round机制 按顺序投递的方式

## 2.4 Consumer Group

同一个Topic的消息在同一个Consumer Group中的一个Consumer消费，但是多个Consumer Group可以重复消费。一个partition只能被一个consumer拉取消息。**所以当consumer的数量大于partition的数量后，再增加consumer的数量将起不到作用。**

![](https://medesqure.oss-cn-hangzhou.aliyuncs.com/img/20200713213704.png)

一般来说，在配置时一台服务器都会创建一个group instance实例，然后启动多线程去批量拉取消息。这个instance会维护一个offset，批量拉取消息并分发给多线程。

**一般来说，kafka的消息在一个组内只能被消费一次。除非在消费者的reblance会重复消费的情况。如果需要实现广播的功能，可以把消费者放在不同的消费者组内，确保每个消费者都能消费一遍。**

## 2.5 KAFKA消息投递的保证

- producer向broker发送消息
  **通过replica保证了HA。producer向broker发送消息后broker先存储并写到replica，然后提交commit。如果没有发送那么producer就会重复发送。所以消息可能会重复发送，但是保证消息不会丢失。**

- broker 到consumer的消息投递保证

  有2中情况，拉取消息后立马commit 消息可能会丢失。如果处理完消息后在commit 消息会有重复消费的问题。一般是在数据库中做业务的幂等处理来实现。消息本来就会有重复消费的问题。





分享系统重构

1.梳理原有系统架构和业务逻辑，设计新系统的架构模型。

2.完成分享系统的重构，并验证原有功能。





参考 https://tech.meituan.com/2015/01/13/kafka-fs-design-theory.html

https://www.shuzhiduo.com/A/mo5k0e94dw/