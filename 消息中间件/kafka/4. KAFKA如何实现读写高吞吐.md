[TOC]

# 1. 消息磁盘顺序写

Kafka的设计不是在内存中保存数据，在需要时将数据flush到磁盘中。而是采用相反的事情，将数据立即写入到文件系统并持久化到磁盘中，不进行任何系统调用。意味着数据被传输到OS内核中的页面缓存中，OS异步将数据刷新到磁盘中。

 顺序写磁盘的速度和写网络的速度一样快。在磁盘中线性写入的速度为600M/s，而随机写入的速度为100K/s

## 1.1 磁盘顺序写

kafka是写数据到磁盘中，磁盘的转速较慢，寻址需要花费大量的时间。如果是随机IO，磁盘会进行频繁的寻址导致写入的效率很低。KAFKA使用顺序IO来提高了写磁盘的效率。**kafka会将数据追加写入Partition的Segment的结尾**。因为对segment文件是追加写，所以实现了磁盘文件的顺序写，避免了磁盘随机写的寻址的开销。而且是追加写，写入的速度和磁盘文件大小无关。这样会导致数据无法被删除，时间长会导致磁盘被写满。kafka提供了按照插入时间和partition大小来删除。

## 1.2 页缓存 PageCache

消息写入虽然是磁盘顺序写入，没有磁盘寻址的开销。但是每一条消息都执行磁盘写入，也会造成大量的磁盘IO。

所以broker在写消息使用了MMAP技术，即内存映射文件。消息先写入到OS的页缓存中，由页缓存刷新到磁盘文件中。不需要在用户空间到内核空间拷贝信息。

将消息写入到PageCache中，但是页缓存数据刷新到磁盘中的时机由操作系统控制。OS通过后台线程每5s检查一次PageCache的脏数据情况，如果超过指定时间或者指定大小就将数据刷新到磁盘中。但是此时broker宕机了，那么页缓存的数据就会丢失。

![](https://medesqure.oss-cn-hangzhou.aliyuncs.com/img/20200714011756.png)

### 1.2.1 PageCache的优缺点

优点：

1. 减少内存开销  java对象的内存开销很大
2. 避免GC问题 因为使用直接内存所以需要java的GC，不会存在垃圾回收导致的系统卡顿
3. 简单可靠  OS会将所有的空闲内存都作为PageCache，并做了大量的优化 所有可以大量的写内存操作。
4. 当kafka进程重启后，PageCache不会丢失。但是机器宕机了，这部分的数据就丢失了。

因此，使用PageCache的效果会比自己在内存中维护缓存的效果好更多。

同时，可以读写空中接力。

- 当写操作发生时，它是将数据写入到PageCache中，并将页置为dirty
- 当此时读操作发生时，首先在PageCache中查找内容，如果存在就直接返回。否则在磁盘读写数据到PageCache后再返回。

当读写的速度差不多时，消费者是可以直接读取PageCache的数据而不用在磁盘读取数据。并且没有在用户空间维护一份消息数据，节省了一倍的空间。pageCache没有GC可以使用大量的内核内存。

> page Cache是一Radio数，每个节点都是4K大小的page。所以可以通过文件的偏移量快速定位到page。

缺点：

**因为PageCache是异步刷新到磁盘中的，所有会存在数据丢失的风险。**

**Kafka不怕丢，因为它的持久性是靠replicate保证，重启后会从原来的replicate follower中拉缺失的数据。**

因为数据是异步写回到磁盘中，所以当OS Crash(不是进程crash) 数据会丢失。

pageCache写回到磁盘的机制是内核线程 负责将现有dirty的所有页面发送给IO调度。内核会为每个磁盘都启动一个pdFlush线程，每隔5s就唤醒一次。刷新的时机如下

- pageCache dirty的时间超过30s，就将页面刷新到磁盘中。所以crash会丢失30s的数据。
- pageCache的所有dirty页面总大小超过所有的10%的可用内存，就后台刷新到磁盘中。不会影响当前的写PageCache操作。
- 当pageCache的所有dirty页面总大小超过10%的总内存，就是写入的速度太快了，就将写操作block。并且执行flush写磁盘，防止丢失太多的数据。

### 1.2.2 Page Cache的清理策略

当内存满了后，就要清理Page Cache，或者将应用的内存swap到文件中。在linux中可以配置系数0-100，表示使用swap还是清理pageCache。

**page Cache的清除采用的LRU的升级版 LRU-K。防止批量拉取新数据导致LRU的数据都变成脏数据。存在2个队列，一个是存放新的Page，一个是存放访问多次老的page。在清理时从新Page的尾部开始清理。**

### 1.2.3 预读策略

当kafka的消费者速度太慢，在内存中会堆积大量的内容。Page Cache会被清理掉。这时消费者就会读磁盘。这时会采用预读策略，即一页4Kb，那么会预先读出32K的数据。**这个思想在CPU读数据也用到**

### 1.2.4 IO调度层优化

IO调度层在写磁盘主要做了2个的优化 1.合并 2.排序

合并是比如读取扇区1，2，3 那么就合并成读取扇区1-3的操作

**排序 是将所有的操作按照扇区方向排成一个队列，让磁盘的磁头按照顺序移动，减少磁盘寻址这个最慢的操作**

排序会造成读取的不公平，因为有个应用在2个相邻的扇区疯狂写盘，那么其他的应用就无法获取资源。这个在os上做了优化。



# 2. 零拷贝

**一把情况下发送文件是先将文件从磁盘读取到内核空间，再从内核空间复制到用户空间，再从用户空间复制到内核空间并通过网卡发送。**

**零拷贝是从磁盘复制到内核空间，内核空间直接发送网卡。省去了2次的到用户空间复制的时间浪费。**

# 3. 批量发送&数据压缩

KAFKA支持批量发送消息。producer发送消息时，会将消息缓存在本地，再批量发送到kafka

kafka的producer在发送消息前会对消息进行压缩，减少网络传输的压力。consumer端对消息要进行解压，增加了CPU的工作，但是提高了吞吐量。



# 4.总结: KAFKA提高吞吐量的方法

1、Kafka读写磁盘是顺序磁盘IO，一个consumer在消息流（或分区）中只有一个位置。

2、kafka不存在消息的状态，即消息是否被消费。kafka的做法是consumer保存了topic各分区中的位置offset。由consumer控制消费的进度。

3、批量发送消息

4、零拷贝&PageCache 写消息是写在PageCache，由OS异步写入磁盘。读消息采用零拷贝。

## 5. 常见的问题

- kafka采用写文件的方式是否比传统的写内存方式效率低

kafka使用MMP技术在读写数据都是发生在pageCache当中，是OS启动后台线程去异步刷新到磁盘当中。不在写数据的流程中。并且顺序读数据大部分会命中PageCache。因为OS有预读机制，所以缓存基本能命中。因此，读写的性能在原理上得到保证。

- 多个partition的多个文件同时读写会不会降低性能
  - 读写数据是发生在PageCache，flush是发生在异步线程中。所以不会对性能不会有影响。**除非PageCache占用内存过大，或者页交换导致消耗了CPU时间**
  - 文件都是顺序读写，OS层面有预读机制和后写机制，**会对pageCache做排序和合并。保证磁盘会按照顺序移动，减少磁盘寻址这个最慢的操作。**不会出现文件过多导致成为随机读写磁盘。但是当脏页的数量过多还是会影响性能。
  - 在写入数据并发过高，就会导致pageCache很大，大量触发磁盘IO，就会导致同步刷新FLUSH阻塞写进程，对主流程造成影响。

- 使用SSD不能改善KAFKA的读写性能

因为读写都是发生在PageCache中，在后台异步刷新到磁盘中。KAFKA的任何操作都不会等待磁盘同步。所以KAFKA的partition至少要有3个副本，否则broker奔溃容易导致数据丢失。

消息异步写磁盘都是顺序IO，操作系统已经做了大量的优化。

# 6. Linux的mmap内存映射原理

## 6.1 mmap的原理

mmap是内存映射方法，将一个文件或者其他对象映射到进程的地址空间。实现了文件磁盘地址到虚拟地址空间的虚拟地址的映射关系。如图所示

![](https://medesqure.oss-cn-hangzhou.aliyuncs.com/img/20200715162507.png)

函数原型

```c
 void *mmap(void *addr, size_t length, int prot, int flags, int fd, off_t offset);
```

其中 addr是映射返回的虚拟地址  fd是文件描述符

实现映射后，进程采用的是指针的方式直接读写这一段内存，OS会在合适的时机将脏页协会到对应的文件磁盘中。而不需要使用read、write等系统调用。

mmap不需要系统调用，并且还减少了内存的拷贝次数。从内核态的pageCache拷贝到用户态的buffer的来回拷贝开销。

mmap适用于对一块内存磁盘频繁读写的场景。比如partition的segment文件存储了消息。我们要频繁读写这块磁盘。可以把这个文件通过mmap映射到pageCache中。然后修改再由OS后台将数据刷回磁盘。应用也可以自己同步刷盘。

在映射到的是虚拟地址，不用担心映射的文件太大。

1. 所有进程共享的是物理内存，每个进程都拥有自己的虚拟地址并映射到物理地址。
2. 每个进程分配的4G内存使虚拟地址。在访问时都要转化成物理地址。

![](https://medesqure.oss-cn-hangzhou.aliyuncs.com/img/20200715163422.png)

## 6.2 使用mmap和普通IO的对比

![](https://medesqure.oss-cn-hangzhou.aliyuncs.com/img/20200715163731.png)

**可以看出使用普通IO是存在系统调用的，而mmap是通过指针的方式直接读取内存。**

mmap的使用

1. 大数据量文件的读取，有效提高磁盘和内存间数据同行的性能
2. 进程间的共享内存。实现高效的单机进程间的通信。

在数据量很小的情况下，使用mmap和普通IO的性能差不多。



参考 https://juejin.im/post/5cecdcc06fb9a07ecb0b88b5 mmap的原理

