[toc]
# # 1.集群组件

1. NameServer NameServer负责

![img](https://medesqure.oss-cn-hangzhou.aliyuncs.com/img/20200720201125.png?ynotemdtimestamp=1595436859525)

# 4.RocketMq的消息存储

消息发送的时序图

![](https://medesqure.oss-cn-hangzhou.aliyuncs.com/img/20200724111650.png)

## 4.1 存储简介

业务系统需要MQ有持久化存储的能力，能大大增加系统的可用性。在存储效率和方式来看，从效率看文件系统高于KV系统，高于关系型数据库。从可靠性看是相反的。

**RocketMq的单broker上所有topic的消息都是存储在一个CommitLog文件上。consumeQueue是逻辑队列，存储着消息的索引。**

1. CommitLog 消息存储文件，所有topic的消息都存储在该文件中。每台Broker的commitLog文件被本机所有的Topic所共享。
2. Consume Queue相当于kafka中的partition，是一个逻辑队列，存储了这个Queue在CommiLog中的起始offset，log大小和MessageTag的hashCode。
3. 每次读取消息队列先读取consumerQueue,然后再通过consumerQueue去commitLog中拿到消息主体。

![img](https://medesqure.oss-cn-hangzhou.aliyuncs.com/img/20200720214649.png?ynotemdtimestamp=1595436859525)

## 4.2 MQ和Kafka的存储方式的区别

和RocketMQ类似，每个Topic有多个partition(queue)，kafka的每个partition都是一个独立的物理文件，消息直接从里面读写。

![img](https://medesqure.oss-cn-hangzhou.aliyuncs.com/img/20200721132935.png?ynotemdtimestamp=1595436859525)

一旦kafka中Topic的partitoin数量过多，队列文件会过多，会给磁盘的IO读写造成很大的压力，造成tps迅速下降。**顺序写磁盘会变成随机写磁盘**

> kafka的吞吐量高，每个topic都有自己的partition文件。但是对topic的并发度不高。当topic过大时，kafka的性能会急剧下降。而RocketMq的吞吐量没有kafka高，因为加锁写单个文件，但是可以支持的topic很高。

- **MQ的优点** 队列轻量化，单个队列数据量非常少。对磁盘的访问串行化，避免磁盘竟争，不会因为队列增加导致IOWAIT增高。
- MQ的缺点
  1. 写虽然完全是顺序写，但是读却变成了完全的随机读。有PageCache和预读策略，也不会出现大量的IO读。
  2. 读一条消息，会先读ConsumeQueue，再读CommitLog，增加了开销。
  3. 要保证CommitLog与ConsumeQueue完全的一致，增加了编程的复杂度。
- 优化思路
  1. 增大内存，让pageCache尽可能的缓存更多的数据，减少IO操作。
  2. 数据预加载策略 访问时，即使只访问1k的消息，系统也会提前预读出更多数据，在下次读时，就可能命中内存。
  3. 系统的IO调度算法优化 OS在IO调度的算法优化上已经做了很多。**在读取多个pageCache时，IO的算法会将其进行排序和合并。将完全随机改成顺序跳跃的方式。可以大大减少磁盘寻址这个最最最慢的操作。**顺序跳跃方式读较完全的随机读性能会高5倍以上。另外4k的消息在完全随机访问情况下，仍然可以达到8K次每秒以上的读性能。

因此，Consume Queue存储数据量极少，而且是顺序读，在PAGECACHE预读作用下，Consume Queue的读性能几乎与内存一致，即使堆积情况下。所以可认为Consume Queue完全不会阻碍读性能(相比于kafka的机制还是会慢一些)。**Commit Log中存储了所有的元信息，包含消息体，所以只要有Commit Log在，Consume Queue即使数据丢失，仍然可以恢复出来。**

## 4.3 MQ的文件存储

整体流程图如下所示

![](https://medesqure.oss-cn-hangzhou.aliyuncs.com/img/20200724111650.png)



### 4.3.1 CommitLog 文件

CommitLog的文件存储逻辑如下，所有的Topic是混合存储在一个队列里。每一条消息的前面4个字节存储了该消息的总长度。

![img](https://medesqure.oss-cn-hangzhou.aliyuncs.com/img/20200721210303.png?ynotemdtimestamp=1595436859525)

在查找消息时先根据offset查找消息的起始位置，读取消息的长度。再去捞出单条消息的长度。

### 4.3.2 ConsumeQueue 文件

消费者不会直接去消费commitLog文件中查找订阅主题下的消息。而是采用ConsumeQueue队列索引。

每一个Topic都会有一个ConsumeQueue文件夹，这个是分为QueueId分文件夹的。可以看成是kafka的partition。**这里有0-3是说明1个broker里面存储了4个分片**。

**consumeQueue是一个文件夹，第一级目录是topic，第二级目录是主题的消息队列。**

![img](https://medesqure.oss-cn-hangzhou.aliyuncs.com/img/20200721214456.png?ynotemdtimestamp=1595436859525)

每个消息的存储格式如下所示。

![img](https://medesqure.oss-cn-hangzhou.aliyuncs.com/img/20200721214208.png?ynotemdtimestamp=1595436859525)

每个ConsumeQueue文件包含30w条记录，可以看成是索引数组。每个文件的长度是30W*20个字节。

**消息消费进度存储的偏移量是逻辑偏移量**。

计算的方式是根据传入的逻辑偏移Index，Index*20得到consumeQueue的物理偏移量。如果小于minLogicOffset，说明文件已经被删除。如果大于minLogicOffset就定位到具体的物理文件，然后再取模得到在文件中的偏移量，定位到该消息的物理偏移量。

## 4.3.3 Index索引文件

Index索引文件是Hash索引机制为消息建立索引。可以根据消息的Key快速查找出消息所在的位置。类似于HashMap。这个就不详细说了

![img](https://medesqure.oss-cn-hangzhou.aliyuncs.com/img/20200721215403.png?ynotemdtimestamp=1595436859525)

## 4.4 消息存储的原理

### 4.4.1 关键类

- DefaultMessageStore          消息存储的最重要类，包含很多消息文件操作API。
- CommitLog                            CommitLog文件的存储实现类
- IndexService                          索引文件实现类
- ReputMessageService          CommitLog消息分发，根据CommitLog文件构建ConsumeQueue、IndexFile文件
- MappedFile                           每个MappedFile对应的是物理上的磁盘文件的内存映射。
- MappedFileQueue              维护了MappedFile数组

![img](https://medesqure.oss-cn-hangzhou.aliyuncs.com/img/20200721132958.png?ynotemdtimestamp=1595436859525)

### 4.4.2 消息发送的流程

1. 如果当前的broker停止工作或slave模式或磁盘满，拒绝写入消息。消息不能超过65536个字符。
2. 如果是延时消息，走延时消息的投递逻辑。
3. 获取当前可以写入的CommitLog文件。每个文件默认1G，以偏移量作为文件名。
4. 在写入CommitLog时先申请Lock，即是串行操作的。**kafka是按照topic的partition并发。**
5. 设置消息的存储时间，获取MapedFile当前指针将消息append到MapedFIle中并更新position。**将消息内容存储到ByteBuffer并创建AppendMessageResult。**由OS来执行异步刷盘的操作。
6. 创建全局唯一的消息ID，组成为IP+port+offset。**所以根据MsgId可以直接查找消息。**
7. 处理完消息后释放Lock。消息此时只是追加到内存中。再根据同步刷盘或者异步刷盘策略持久化到磁盘中。

### 4.4.3 MappedFile内存映射文件

改类是内存映射文件的具体实现。维护了

1. OS_PAGE_SIZE      					操作页的大小 默认是4K
2. committedPosition和FlushedPosition              文件提交位置和刷盘位置
3. FileChannel                             文件通道
4. ByteBuffer                 堆内存，数据可以先存在堆内存中。再提交到MappedFile对应的内存映射文件Buffer。
5. MappedByteBuffer         虚拟内存    物理文件对应的内存映射buffer
6. TransientStorePool          堆内存池

注: 当TransientStorePoolEnable为true启用堆内存池。数据是存储在堆内存。在通过Commit线程将数据提交到MappedByteBuffer，再通过OS的Flush线程持久化到磁盘中。否则是将数据直接写在MappedByteBuffer

## 4.4.4 MapedFileQueue映射文件队列查找消息

MapedFileQueue维护了连续的多段内存映射

1. MappedFile文件集合
2. flushedWhere 当前刷盘指针，该指针之前的数据全部持久化到磁盘中
3. commitedWhere 数据提交指针，内存中ByteBuffer当前的写指针。

- 按照消息存储时间查找

  遍历所有的MappedFile列表，找到第一个最后更新时间大于待查找的文件。

- 按照消息偏移量offset查找

  获取当前的最小偏移量和最大偏移量再二分查找。

### 4.4.5 TransientStorePool 的作用

短暂的堆内存池。作用是用来零时缓存数据。数据先被写入byteBuffer堆内存中，然后采用commit线程定时将数据从堆内存复制到MappedByteBuffer当中。再由Flush线程将数据写到文件中。**采用该策略是为了将堆外内存一直锁定在内存中，防止被进程将内存交换到磁盘中。**

### 4.4.6 MappedFile 文件Commit

commit的作用是将MappedFile#writeBuffer的数据提交到文件通道FIleChannel当中。

步骤如下:

1. 判断当前是否可以提交(脏页是否达到提交的最少页数commitLeastPages)
2. 获取当前需要提交的数据的起始地址和结束地址
3. 如果有byteBuffer，那么commit的作用就将该数据写到fileChannel并更新偏移地址。

```
protected boolean isAbleToCommit(final int conunitLeastPages) { 
  int flush= this.conunittedPosition.get();
	int write = this .wrotePosition.get();
	if (this.isFull()) {
		return true;
	if (conunitLeastPages > 0) {
		return ((write / OS_PAGE_SIZE) - (flush / OS_PAGE_SIZE)) >= commitLeastPages; 
    }
    return 	write > flush;
}
public int commit(final int commitLeastPages) {
	if (writeBuffer == null) {
  		return this.wrotePosition.get();
  	if (this.isAbleToCommit(conunitLeastPages)) { 
      if (this.hold()) {
          commit0(conunitLeastPages);
          this.release(); 
      } else {
          log.warn(”in conunit, hold failed, conunit offset =”+ 		this.conunittedPosition.get());
          if (writeBuffer != null && this.transientStorePool != null && this.fileSize == this.conunittedPosition.get()) {
              this.transientStorePool.returnBuffer(writeBuffer); 
              this.writeBuffer = null;
          }
          return this.conunittedPosition.get();
      }
}
```

在commit0里做具体的数据提交，代码如下

```
protected void commit0(final int conunitLeastPages) {
    int writePos = this.wrotePosition.get();
    int lastConunittedPosition = this.conunittedPosition.get();
    if (writePos - this.conunittedPosition.get() > 0) {
        try {
            ByteBuffer byteBuffer = writeBuffer.slice();
            byteBuffer.position(lastCommittedPositi on);
            byteBuffer.limit(writePos);
            this.fileChannel.position(lastCommittedPosition);
            this.fileChannel.write (byteBuffer);
            this.committedPostion.set(writePos);

        } catch (Throwable e) {
            工 cg.error （” Error occurred when commit data to FileChannel. ”, e)
        }
    }
}
```

### 4.4.7 MappedFile Flush机制

MappedFile 的刷写磁盘很简单，直接调用mappedByteBuffer或者fileChannel的force方法将内存中的数据持久化到磁盘中。如果ByteBuffer为空，那么数据是直接写到MappedByteBuffer，否则数据是先写到ByteBuffer。

## 4.5 更新ConsumeQueue和Index

在一个broker的每个topic可能会存在多个ConsumeQueue队列，采用QueueId来标记。

Broker在启动时会启动ReputMessageService线程，并初始化了**reputFormOffset**，该值标记了CommitLog的更新的位置。该线程每1ms会尝试推送消息到ConsumeQueue和Index文件。更新的步骤如下

1. 返回reputFromOffset开始的全部有效数据(commitlog文件)并循环读取每一条消息。
2. 从byteBuffer中循环读取消息，根据消息的topic和QueueId获取对应的consumeQueue
3. 将消息的offset，长度，tag写入到ByteBuffer，将内容追加到ConsumeQueue的内存映射文件中。由OS异步刷盘。

## 4.6 MQ的刷盘原理

MQ的存储是基于JDL的NIO中的特殊ByteBuffer (MappedByteBuffer)。消息是直接追加到内存中，然后再根据刷盘策略调用force()方法进行刷盘。

- 如果是同步刷盘，将消息追加到内存后，将同步调用MappedByteBuffer的force()方法。
- 如果是异步刷盘，将消息追加到内存后立即返回。MQ会单独使用线程定时执行刷盘操作。

### 4.6.1 JDK的IO和NIO说明

主要区别如下

1. IO是面向流，NIO是面向缓冲区的。java IO每次都要读取所有的字节不能缓存在任何地方。NIO是将数据读取到可以稍后处理的缓冲区中。
2. java IO流是阻塞的，当线程发起read()或者write()操作后就阻塞直到数据被操作完毕。NIO是非阻塞的，从channel读取数据时如果没有数据就立即返回。
3. Selectors java NIO使用selector线程来监视多个通道。这种机制使一个线程可以管理多个channel

NIO中也有2种Buffer。

1. ByteBuffer 堆内存缓冲区。在数据量少的时候可以使用。
2. MappedByteBuffer 文件映射。 在数据量大时，比如1G的文件，可以将文件直接映射到内存中(虚拟内存)。通常可以直接映射整个文件，如果文件较大，可以进行分段映射。

这是NIO中的DirectBuffer和MappedByteBuffer来提高IO效率

DirectBuffer占用的是堆外内存，JVM会使用Native IO操作。使用DirectBuffer可以避免额外的数据复制，提高IO效率，同时减少GC的工作量。

MappedByteBuffer其实也是DirectBuffer，但是是将文件内容映射到内存中。省去了内核空间到用户空间的拷贝。

```java
ByteBuffer buffer =  ByteBuffer.allocateDirect(1024);  
MappedByteBuffer buffer = fileChannel.map(MapMode.READ_ONLY, 0, 1024);  
```



![](https://medesqure.oss-cn-hangzhou.aliyuncs.com/img/20200724010643.png)

### 4.6.2 刷盘流程

针对commitLog，MQ提供了2种刷盘的方式。

#### 4.6.2.1 同步刷盘流程

同步刷盘采用的是producer-consumer模型。消息被追加到MappedFile后立即将数据从内存刷到磁盘中。**由CommitLog类的handleDIskFlush实现。** 步骤如下

1. 构建GroupCommitRequest同步任务请求并提交到GroupCommitService。
2. producer调用阻塞等待刷盘结果，超时时间为5s
3. GroupCommitService 线程处理GroupCommitRequest对象后就调用wakeUpCustomer方法唤醒producer。

![](https://medesqure.oss-cn-hangzhou.aliyuncs.com/img/20200723013031.png)

具体的代码如下

- Commitlog#handleDiskFlush   提交刷盘任务

```java
void handleDiskFlush() {
  //.....
  final GroupCommitService service = (GroupCommitService) this.flushCommitLogService;
  GroupCommitRequest request= new GroupCommitRequest(result.getWroteOffset() +
                                                     result.getW 	roteBytes());
  service.putRequest(request); //提交刷盘request
  boolean flushOK = request.waitForFlush(  //开始同步等待返回结果
    this.defaultMessageStore.getMessageStoreConfig().getSyncFlushTimeout();	
    if( !flushOK){
      putMessageResult.setPutMessageStatus(PutMessageStatus.FLUSH DISK TIMEOUT);
    }
}
```

- GroupCommitRequest   

```java
//GroupCommitRequest
public static class GroupCommitRequest {
  //这次请求要刷到的offSet位置，比如已经刷到2，
  private final long nextOffset;
  //控制flush的拴
  private final CountDownLatch countDownLatch = new CountDownLatch(1);
  private volatile boolean flushOK = false;

  //刷完了唤醒
  public void wakeupCustomer(final boolean flushOK) {
    this.flushOK = flushOK;
    this.countDownLatch.countDown();
  }
  
  public boolean waitForFlush(long timeout) {
    try {
      this.countDownLatch.await(timeout, TimeUnit.MILLISECONDS);
      return this.flushOK;
    } catch (InterruptedException e) {
      e.printStackTrace();
      return false;
    }
  }
}
```

- GroupCommitService   启动线程做具体的刷盘任务

为了避免同步刷盘任务和其他producer提交的任务直接的锁竞争，提供了读List和写List。每次将读List先拷贝到写List中再去消费。

GroupCommitService每处理一批同步刷盘请求后就会休眠10ms

执行刷盘操作就是调用MappedFileQueue的flush的flush操作，即MappedByteBuffer的flush操作。

处理完刷盘任务后腰更新checkpoint刷盘点。

```java
class GroupCommitService extends FlushCommitLogService {
    //用来接收消息的队列，提供写消息
    private volatile List<GroupCommitRequest> requestsWrite = new ArrayList<GroupCommitRequest>();
    //用来读消息的队列，将消息从内存读到硬盘
    private volatile List<GroupCommitRequest> requestsRead = new ArrayList<GroupCommitRequest>();

    //添加一个刷盘的request
    public void putRequest(final GroupCommitRequest request) {
        synchronized (this) {
            //添加到写消息的list中
            this.requestsWrite.add(request);
            //唤醒其他线程
            if (!this.hasNotified) {
                this.hasNotified = true;
                this.notify();
            }
        }
    }

    //交换读写队列，避免上锁
    private void swapRequests() {
        List<GroupCommitRequest> tmp = this.requestsWrite;
        this.requestsWrite = this.requestsRead;
        this.requestsRead = tmp;
    }

	//具体的刷盘doCommit
    private void doCommit() {
      for (GroupCommitRequest req : this.requestsRead) {
        boolean flushOK = false;
        for (int i = 0; (i < 2) && !flushOK; i++) {
          flushOK = (CommitLog.this.mapedFileQueue.getCommittedWhere() >= req.getNextOffset());
          if (!flushOK) {
            CommitLog.this.mapedFileQueue.commit(0);
          }
        }
        req.wakeupCustomer(flushOK);
      }

      long storeTimestamp = CommitLog.this.mapedFileQueue.getStoreTimestamp();
      if (storeTimestamp > 0) {
        CommitLog.this.defaultMessageStore.getStoreCheckpoint().setPhysicMsgTimestamp(storeTimestamp);
      }
    }

  //
    public void run() {
        CommitLog.log.info(this.getServiceName() + " service started");
        while (!this.isStoped()) {
            try {
                this.waitForRunning(0);
                this.doCommit();
            } catch (Exception e) {
                CommitLog.log.warn(this.getServiceName() + " service has exception. ", e);
            }
        }
    }
```

#### 4.6.2.2 异步刷盘流程

异步刷盘在开启transientStorePoolEnable机制会有区别。如果开启后，MQ会申请一个和commitLog文件一样大小的堆外内存，并且将该内存进行锁定确保不会被置换到虚拟内存中去。消息先被追加到堆外内存，再提交到内存映射中，最后才flush到磁盘中。步骤如下

1. 将消息追加到ByteBuffer(DirectByteBuffer)，wrotePosition往后移动
2. CommitRealTimeService线程每200ms将ByteBuffer更新的内容提交到MappedByteBuffer中。
3. FlushRealTimeService默认500ms将MappedByteBuffer中将新追加的内容写到磁盘中。













https://juejin.im/entry/58aac53e8d6d810058b85f53

https://juejin.im/post/5ba798995188255c806663c0

https://juejin.im/post/5dde435ce51d4541c24658cb

https://juejin.im/entry/581995e3a22b9d0067a317cf